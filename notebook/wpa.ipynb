{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import LayoutLMv3Tokenizer, AutoConfig\n",
    "\n",
    "sys.path.append('../src')\n",
    "from model import My_DataLoader\n",
    "from model.LayoutLMv3forMIM import LayoutLMv3ForPretraining\n",
    "from utils import masking_generator, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--tokenizer_vocab_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--input_file\", type=str, required=True)\n",
    "parser.add_argument(\"--model_params\", type=str)\n",
    "parser.add_argument(\"--ratio_train\", type=float,default=0.9)\n",
    "parser.add_argument(\"--output_model_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--output_file_name\", type=str, required=True)\n",
    "parser.add_argument(\"--model_name\", type=str, required=True)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=2)\n",
    "parser.add_argument(\"--leaning_rate\", type=int, default=1e-5)\n",
    "parser.add_argument(\"--max_epochs\", type=int, default=1)\n",
    "args_list = [\"--tokenizer_vocab_dir\", \"../data/vocab/tokenizer_vocab/\",\"--input_file\",\n",
    "            \"../data/preprocessing_shared/30000data_10000_split/\",\n",
    "            \"--output_model_dir\", \"../data/train/model/\", \\\n",
    "            \"--output_file_name\", \"model.param\", \\\n",
    "            \"--batch_size\", \"4\", \\\n",
    "            \"--model_name\", \"microsoft/layoutlmv3-base\"]\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LayoutLMv3Tokenizer(f\"{args.tokenizer_vocab_dir}vocab.json\", f\"{args.tokenizer_vocab_dir}merges.txt\")\n",
    "ids = range(tokenizer.vocab_size)\n",
    "vocab = tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_bbox = utils.init_visual_bbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_bbox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.input_file + \"0.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23274"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.pkl\n",
      "10000.pkl\n",
      "20000.pkl\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "input_names = os.listdir(args.input_file)\n",
    "for file_name in input_names:\n",
    "    print(file_name)\n",
    "    with open(f\"{args.input_file}{file_name}\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "        data += d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23274"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[] + [1, 3 ] + [4, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  args.model_params is not None:\n",
    "    model = torch.load(args.model_params)\n",
    "else:\n",
    "    config = AutoConfig.from_pretrained(args.model_name)\n",
    "    config.num_visual_tokens = 8192\n",
    "    model = LayoutLMv3ForPretraining(config)\n",
    "    # Roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "    # ## embedidng 層の重みをRobertaの重みで初期化\n",
    "    # weight_size = model.state_dict()[\"model.embeddings.word_embeddings.weight\"].shape\n",
    "    # for i in range(weight_size[0]):\n",
    "    #   model.state_dict()[\"model.embeddings.word_embeddings.weight\"][i] = \\\n",
    "    #   Roberta_model.state_dict()[\"embeddings.word_embeddings.weight\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20946 2328\n"
     ]
    }
   ],
   "source": [
    "n_train = math.floor(len(data) * args.ratio_train)\n",
    "train_data = data[:n_train]\n",
    "valid_data = data[n_train:]\n",
    "print(len(train_data), len(valid_data))\n",
    "\n",
    "my_dataloader = My_DataLoader.My_Dataloader(vocab)\n",
    "train_dataloader = my_dataloader(train_data, batch_size=args.batch_size, shuffle=True)\n",
    "valid_dataloader = my_dataloader(valid_data, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 196, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([4, 196, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/hikaru-si/.pyenv/versions/3.8.6/envs/exp_005/lib/python3.8/site-packages/transformers/modeling_utils.py:713: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bahcclcsb02/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         text_logits, image_logits, wpa_logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(inputs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bahcclcsb02/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bahcclcsb02/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m x\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "model.train()\n",
    "for epoch in range(args.max_epochs):\n",
    "    for iter, batch in enumerate(train_dataloader):\n",
    "        # inputs = {k: v.to(f'cuda:{model.device_ids[0]}') for k in [\"input_ids, bbox\", \"pixel_values\", \"attention_mask\"]}\n",
    "        inputs = {k: batch[k] for k in [\"input_ids\", \"bbox\", \"pixel_values\", \"attention_mask\", \"bool_mi_pos\"]}\n",
    "        text_logits, image_logits, wpa_logits = model.forward(inputs)\n",
    "        break\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 512]), torch.Size([4, 512]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"alignment_label\"].shape, batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3386499572.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [8]\u001b[0;36m\u001b[0m\n\u001b[0;31m    wpa_logits.\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "wpa_logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_visual_bbox(img_size=(14, 14), max_len=1000):\n",
    "    #torch div : divide\n",
    "    visual_bbox_x = torch.div(torch.arange(0, max_len * (img_size[1] + 1), max_len),\n",
    "                              img_size[1], rounding_mode='trunc')\n",
    "    visual_bbox_y = torch.div(torch.arange(0, max_len * (img_size[0] + 1), max_len),\n",
    "                              img_size[0], rounding_mode='trunc')\n",
    "    visual_bbox = torch.stack(\n",
    "        [\n",
    "            visual_bbox_x[:-1].repeat(img_size[0], 1),\n",
    "            visual_bbox_y[:-1].repeat(img_size[1], 1).transpose(0, 1),\n",
    "            visual_bbox_x[1:].repeat(img_size[0], 1),\n",
    "            visual_bbox_y[1:].repeat(img_size[1], 1).transpose(0, 1),\n",
    "        ],\n",
    "        dim=-1,\n",
    "    ).view(-1, 4)\n",
    "    return visual_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_bbox = _init_visual_bbox()\n",
    "visual_bbox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x0, y0, x1, y1) x0, y0比較\n",
    "def is_content_bbox(text_bbox, image_bbox):\n",
    "    if (text_bbox[0] >= image_bbox[0] and text_bbox[1] >= image_bbox[1] \n",
    "      and text_bbox[0] <= image_bbox[2] and text_bbox[1] <= image_bbox[3]):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x0, y0, x1, y1) x1, y1比較\n",
    "def is_content_bbox_2(text_bbox, image_bbox):\n",
    "    if (text_bbox[2] >= image_bbox[0] and text_bbox[3] >= image_bbox[1] \n",
    "      and text_bbox[2] <= image_bbox[2] and text_bbox[3] <= image_bbox[3]):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aligment(text_bbox):\n",
    "    alignment_list = []\n",
    "    for i in range(len(text_bbox)):\n",
    "        alignment = []\n",
    "        for j in range(len(visual_bbox)):\n",
    "            if is_content_bbox(text_bbox[i], visual_bbox[j]):\n",
    "                alignment.append(j)\n",
    "            if is_content_bbox_2(text_bbox[i], visual_bbox[j]):\n",
    "                alignment.append(j)\n",
    "        alignment_list.append(alignment)\n",
    "\n",
    "    return alignment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alignment_label(visual_bbox, text_bbox, bool_mi_pos):\n",
    "    num_text = len(text_bbox)\n",
    "    labels = torch.ones(num_text)\n",
    "    for v_b in visual_bbox[bool_mi_pos]:\n",
    "        for j, t_b in enumerate(text_bbox):\n",
    "            if is_content_bbox(t_b, v_b) or is_content_bbox_2(t_b, v_b):\n",
    "                labels[j] = 0\n",
    "    alignment_label = labels.to(torch.bool)\n",
    "    return alignment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_label = utils.create_alignment_label(visual_bbox, batch[\"bbox\"][0], batch[\"bool_mi_pos\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = batch[\"bool_mi_pos\"][0].unsqueeze(0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bool_mi_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y104sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m bool_mi_pos[\u001b[39m0\u001b[39m][[\u001b[39m44\u001b[39m, \u001b[39m45\u001b[39m]], is_content[\u001b[39m132\u001b[39m], bool_mi_pos[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bool_mi_pos' is not defined"
     ]
    }
   ],
   "source": [
    "bool_mi_pos[0][[44, 45]], is_content[132], bool_mi_pos[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m wpa_alignment \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m indexes \u001b[39min\u001b[39;00m is_content:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m bool_mi_pos[\u001b[39m0\u001b[39m][indexes]\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y105sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m       label \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'is_content' is not defined"
     ]
    }
   ],
   "source": [
    "wpa_alignment = []\n",
    "for indexes in is_content:\n",
    "    if bool_mi_pos[0][indexes].sum().item() == 0:\n",
    "      label = 1\n",
    "    else:\n",
    "      label = 0\n",
    "    wpa_alignment.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visual_bbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## fast!\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m l \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m v_b \u001b[39min\u001b[39;00m visual_bbox[bool_mi_pos[\u001b[39m2\u001b[39m]]:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, t_b \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(text_bbox):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y140sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mif\u001b[39;00m is_content_bbox(t_b, v_b) \u001b[39mor\u001b[39;00m is_content_bbox_2(t_b,v_b):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visual_bbox' is not defined"
     ]
    }
   ],
   "source": [
    "## fast!\n",
    "l = []\n",
    "for v_b in visual_bbox[bool_mi_pos[2]]:\n",
    "    for i, t_b in enumerate(text_bbox):\n",
    "        if is_content_bbox(t_b, v_b) or is_content_bbox_2(t_b,v_b):\n",
    "            l.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bool_mi_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/wpa.ipynb#Y141sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m bool_mi_pos\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bool_mi_pos' is not defined"
     ]
    }
   ],
   "source": [
    "bool_mi_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(512).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#対応する画像がmaskされている 0 False, maskされていない: 1 True\n",
    "def crete_alignment_label(visual_bbox, text_bboxes, bool_mi_pos):\n",
    "    num_batch, num_text, _ = text_bboxes.shape\n",
    "    if num_batch != bool_mi_pos.shape[0]:\n",
    "        print(\"difarent batch size!\")\n",
    "    alignment_labels = []\n",
    "    for i in range(num_batch):\n",
    "        labels = torch.ones(num_text)\n",
    "        for v_b in visual_bbox[bool_mi_pos[i]]:\n",
    "            for j, t_b in enumerate(text_bboxes[i]):\n",
    "                if is_content_bbox(t_b, v_b) or is_content_bbox_2(t_b, v_b):\n",
    "                    labels[j] = 0\n",
    "        alignment_labels.append(labels.to(torch.bool))\n",
    "    return torch.stack(alignment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = crete_alignment_label(visual_bbox, batch[\"bbox\"], batch[\"bool_mi_pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "seq_len = batch[\"attention_mask\"][0].sum().item()\n",
    "print(int(seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([243])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpa_label = la[0][:int(seq_len)]\n",
    "wpa_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([243])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpa_label[][\"\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  9,  10,  23,  24,  25,  26,  27,  28,  34,  35,  36,  44,  45,  46,\n",
       "         76,  77,  78,  79,  80,  91,  92, 105, 106, 107, 108, 115, 116, 117,\n",
       "        118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 134,\n",
       "        135, 136, 137, 138, 139, 140, 141, 142, 182, 191, 192, 193, 194, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"ml_position\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(183)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la[0][batch[\"attention_mask\"][0].to(torch.bool)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_b = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 == sum(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([452, 4])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"bbox\"][0][la[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(10)\n",
    "b = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, b]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " tensor([[514, 686, 538, 700],\n",
       "         [544, 686, 608, 700],\n",
       "         [514, 702, 569, 716]]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l),text_bbox[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([214,   0, 285,  71])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = visual_bbox[bool_mi_pos[0]][0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_index = torch.arange(0, 196)[bool_mi_pos[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196]), torch.Size([512, 4]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"bool_mi_pos\"][1].shape, batch[\"bbox\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196, 4]), torch.Size([196]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_bbox.shape, batch[\"bool_mi_pos\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_label = create_alignment_label(visual_bbox, batch[\"bbox\"][1], batch[\"bool_mi_pos\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" mailcap rules found for type \"image/png\"\n"
     ]
    }
   ],
   "source": [
    "rect = Image.new(\"RGBA\", (1000, 1000), (0, 0, 255))\n",
    "rect_d = ImageDraw.Draw(rect)\n",
    "\n",
    "for b in batch[\"bbox\"][1].tolist():\n",
    "  rect_d.rectangle(b, outline=(0, 255, 0))\n",
    "for b in batch[\"bbox\"][1][al_label].tolist():\n",
    "  rect_d.rectangle(b, fill=(0, 225, 0), outline=(0, 255, 225))\n",
    "for b in visual_bbox[batch[\"bool_mi_pos\"][1]].tolist():\n",
    "  rect_d.rectangle(b, outline=(225, 0, 0))\n",
    "\n",
    "rect.show()\n",
    "rect.save(\"mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 4]), torch.Size([4, 512]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"bbox\"][0].shape, la.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" mailcap rules found for type \"image/png\"\n"
     ]
    }
   ],
   "source": [
    "# from PIL import Image, ImageDraw\n",
    "\n",
    "# rect = Image.new(\"RGBA\", (1000, 1000), (0, 0, 255))\n",
    "\n",
    "# rect_d = ImageDraw.Draw(rect)\n",
    "# rect_d.rectangle(\n",
    "#     [0, 0, 500, 300], fill=(255, 0, 0)\n",
    "# )\n",
    "\n",
    "# rect.show()\n",
    "# rect.save(\"mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = (14, 14)\n",
    "num_masking_patches = 75\n",
    "max_mask_patches_per_block = None\n",
    "min_mask_patches_per_block = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = masking_generator.MaskingGenerator(\n",
    "            window_size, num_masking_patches=num_masking_patches,\n",
    "            max_num_patches=max_mask_patches_per_block,\n",
    "            min_num_patches=min_mask_patches_per_block,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_masked_pos = mask_generator()\n",
    "bool_masked_pos = torch.from_numpy(bool_masked_pos).unsqueeze(0)\n",
    "bool_masked_pos = bool_masked_pos.flatten(1).to(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_masked_pos[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 196])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"bool_mi_pos\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones([1, 196])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 196])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, a]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('exp_005')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46bb9fe42bf29cda1078546925c7ce66ab74e8066732926e47e293312739327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
