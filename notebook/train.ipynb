{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/hikaru-si/.pyenv/versions/3.8.6/envs/exp_005/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "sys.path.append('../src')\n",
    "import  pickle\n",
    "import torch\n",
    "from transformers import LayoutLMv3Tokenizer, AutoConfig, AutoModel, RobertaModel\n",
    "from model import LayoutLMv3forMLM, My_DataLoader\n",
    "from utils import utils\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_constant_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--tokenizer_vocab_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--input_file\", type=str, required=True)\n",
    "parser.add_argument(\"--model_params\", type=str)\n",
    "parser.add_argument(\"--ratio_train\", type=float,default=0.9)\n",
    "parser.add_argument(\"--output_model_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--output_file_name\", type=str, required=True)\n",
    "parser.add_argument(\"--model_name\", type=str, required=True)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=2)\n",
    "parser.add_argument(\"--leaning_rate\", type=int, default=1e-5)\n",
    "parser.add_argument(\"--max_epochs\", type=int, default=1)\n",
    "args_list = [\"--tokenizer_vocab_dir\", \"../data/vocab/tokenizer_vocab/\",\"--input_file\",\n",
    "            \"../data/preprocessing_shared/encoded_dataset.pkl\",\n",
    "            \"--output_model_dir\", \"../data/train/model/\", \\\n",
    "            \"--output_file_name\", \"model.param\", \\\n",
    "            \"--model_name\", \"microsoft/layoutlmv3-base\"]\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"GPU is not available.\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device_ids = list(range(torch.cuda.device_count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LayoutLMv3Tokenizer(f\"{args.tokenizer_vocab_dir}vocab.json\", f\"{args.tokenizer_vocab_dir}merges.txt\")\n",
    "ids = range(tokenizer.vocab_size)\n",
    "vocab = tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.model_params is None:\n",
    "    model = torch.load(args.model_params)\n",
    "else:\n",
    "    config = AutoConfig.from_pretrained(args.model_name)\n",
    "    model = LayoutLMv3forMLM.LayoutLMv3ForMLM(config)\n",
    "    # Roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "    # ## embedidng 層の重みをRobertaの重みで初期化\n",
    "    # weight_size = model.state_dict()[\"model.embeddings.word_embeddings.weight\"].shape\n",
    "    # for i in range(weight_size[0]):\n",
    "    #   model.state_dict()[\"model.embeddings.word_embeddings.weight\"][i] = \\\n",
    "    #   Roberta_model.state_dict()[\"embeddings.word_embeddings.weight\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu only , comment out this cell.\n",
    "model = torch.nn.DataParallel(model, device_ids = device_ids)\n",
    "model = model.to(f'cuda:{model.device_ids[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer \n",
    "optimizer = AdamW(model.parameters(), lr=args.leaning_rate, weight_decay=1e-2, betas=(0.9, 0.98))\n",
    "#cross entropy\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.input_file, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into train and valid\n",
    "n_train = math.floor(len(data) * args.ratio_train)\n",
    "train_data = data[:n_train]\n",
    "valid_data = data[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = My_DataLoader.My_Dataloader(vocab)\n",
    "train_dataloader = my_dataloader(train_data, batch_size=args.batch_size, shuffle=False)\n",
    "valid_dataloader = my_dataloader(valid_data, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_per_epoch = len(train_dataloader)\n",
    "num_warmup_steps = round((iter_per_epoch * args.max_epochs) * 0.048)\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(logits, batch):\n",
    "    t = []\n",
    "    for i in range(len(batch[\"mask_position\"])):\n",
    "        if len(batch[\"mask_position\"][i]) == 0:\n",
    "            continue\n",
    "        t.append(logits[i][batch[\"mask_position\"][i]])\n",
    "    if len(t) == 0:\n",
    "        return \n",
    "    logits = torch.cat(t)\n",
    "    labels = torch.cat(batch[\"mask_label\"])\n",
    "    labels = labels.to(f'cuda:{model.device_ids[0]}')\n",
    "    loss = loss_fn(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    valid_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            inputs = {k: batch[k].to(f\"cuda:{model.device_ids[0]}\") for k in [\"input_ids\", \"bbox\", \"pixel_values\", \"attention_mask\"]}\n",
    "            logits = model.forward(inputs)\n",
    "            loss = cal_loss(logits, batch)\n",
    "            if loss is None:\n",
    "                continue\n",
    "            valid_losses.append(loss.item())\n",
    "            print(loss.item())\n",
    "        return sum(valid_losses) / len(valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_per_epoch = len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/hikaru-si/.pyenv/versions/3.8.6/envs/exp_005/lib/python3.8/site-packages/transformers/modeling_utils.py:713: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LayoutLMv3ForMLM' object has no attribute 'device_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m inputs \u001b[39m=\u001b[39m {k: batch[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(inputs)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m loss \u001b[39m=\u001b[39m cal_loss(logits, batch)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb Cell 17\u001b[0m in \u001b[0;36mcal_loss\u001b[0;34m(logits, batch)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(t)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(batch[\u001b[39m\"\u001b[39m\u001b[39mmask_label\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mdevice_ids[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Belm51/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/exp_005/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LayoutLMv3ForMLM' object has no attribute 'device_ids'"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "model.train()\n",
    "for epoch in range(args.max_epochs):\n",
    "    for iter, batch in enumerate(train_dataloader):\n",
    "        # inputs = {k: v.to(f'cuda:{model.device_ids[0]}') for k in [\"input_ids, bbox\", \"pixel_values\", \"attention_mask\"]}\n",
    "        inputs = {k: batch[k] for k in [\"input_ids\", \"bbox\", \"pixel_values\", \"attention_mask\"]}\n",
    "        logits = model.forward(inputs)\n",
    "        loss = cal_loss(logits, batch)\n",
    "        if loss is None:\n",
    "            continue\n",
    "        # labels = labels.to(f'cuda:{model.device_ids[0]}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        if iter % math.floor(iter_per_epoch*0.01) == 0:\n",
    "            val_loss = validation()\n",
    "            print(iter, loss.item())\n",
    "            print(iter,\"val\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([89])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"mask_position\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.87540340423584\n",
      "1 10.913202285766602\n",
      "2 10.854154586791992\n",
      "3 11.003539085388184\n",
      "4 10.977672576904297\n",
      "5 10.788056373596191\n",
      "6 11.0016450881958\n",
      "7 10.83245849609375\n",
      "8 11.038727760314941\n",
      "9 10.941429138183594\n",
      "10 10.746644020080566\n",
      "11 10.765816688537598\n",
      "12 10.817831993103027\n",
      "13 10.815743446350098\n",
      "14 10.858794212341309\n",
      "15 10.890091896057129\n",
      "16 10.817254066467285\n",
      "17 10.730331420898438\n",
      "18 10.704963684082031\n",
      "19 10.630881309509277\n",
      "20 10.737689971923828\n",
      "21 10.534788131713867\n",
      "22 10.640432357788086\n",
      "23 10.627967834472656\n",
      "24 10.67199993133545\n",
      "25 10.671628952026367\n",
      "26 10.399262428283691\n",
      "27 10.393364906311035\n",
      "28 10.457799911499023\n",
      "29 10.454362869262695\n",
      "30 10.372509956359863\n",
      "31 10.474432945251465\n",
      "32 10.55550765991211\n",
      "33 10.313406944274902\n",
      "34 10.34122371673584\n",
      "35 10.251405715942383\n",
      "36 10.119297981262207\n",
      "37 10.092342376708984\n",
      "38 9.98108959197998\n",
      "39 10.217385292053223\n",
      "40 10.075906753540039\n",
      "41 10.293874740600586\n",
      "42 10.036898612976074\n",
      "43 10.015714645385742\n",
      "44 10.167057991027832\n",
      "45 10.199872970581055\n",
      "46 10.429621696472168\n",
      "47 10.076924324035645\n",
      "48 9.979494094848633\n",
      "49 10.155522346496582\n",
      "50 10.099607467651367\n",
      "51 10.06415843963623\n",
      "52 9.898554801940918\n",
      "53 9.956104278564453\n",
      "54 10.250782012939453\n",
      "55 9.723796844482422\n",
      "56 10.266495704650879\n",
      "57 10.050552368164062\n",
      "58 10.083905220031738\n",
      "59 10.11374568939209\n",
      "60 9.909463882446289\n",
      "61 9.795021057128906\n",
      "62 9.783062934875488\n",
      "63 9.848550796508789\n",
      "64 9.72995376586914\n",
      "65 9.830952644348145\n",
      "66 9.856142044067383\n",
      "67 9.835846900939941\n",
      "68 9.896835327148438\n",
      "69 9.898639678955078\n",
      "70 10.040522575378418\n",
      "71 10.011542320251465\n",
      "72 9.658284187316895\n",
      "73 9.8388032913208\n",
      "74 9.912858009338379\n",
      "75 9.657266616821289\n",
      "76 9.821083068847656\n",
      "77 9.738972663879395\n",
      "78 9.752497673034668\n",
      "79 9.824981689453125\n",
      "80 9.89782428741455\n",
      "81 9.73129940032959\n",
      "82 9.808351516723633\n",
      "83 9.797382354736328\n",
      "84 9.938644409179688\n",
      "85 9.453529357910156\n",
      "86 9.27962875366211\n",
      "87 9.342103958129883\n",
      "88 9.56612491607666\n",
      "89 9.708834648132324\n",
      "90 9.587102890014648\n",
      "91 9.890144348144531\n",
      "92 9.592318534851074\n",
      "93 9.892813682556152\n",
      "94 9.353837013244629\n",
      "95 9.73502254486084\n",
      "96 9.768705368041992\n",
      "97 9.713828086853027\n",
      "98 9.604141235351562\n",
      "99 9.57321834564209\n",
      "100 9.761341094970703\n",
      "101 9.352381706237793\n",
      "102 9.335901260375977\n",
      "103 9.292985916137695\n",
      "104 9.389904975891113\n",
      "105 9.472678184509277\n",
      "106 9.54893684387207\n",
      "107 9.266889572143555\n",
      "108 9.554206848144531\n",
      "109 9.578398704528809\n",
      "110 9.50507926940918\n",
      "111 9.345625877380371\n",
      "112 9.447919845581055\n",
      "113 9.219636917114258\n",
      "114 9.447736740112305\n",
      "115 9.348417282104492\n",
      "116 9.700998306274414\n",
      "117 9.468657493591309\n",
      "118 10.09681510925293\n",
      "119 9.253761291503906\n",
      "120 9.44737434387207\n",
      "121 9.402934074401855\n",
      "122 9.07904052734375\n",
      "123 9.475744247436523\n",
      "124 9.04999828338623\n",
      "125 9.404806137084961\n",
      "126 9.256823539733887\n",
      "127 9.48425579071045\n",
      "128 9.316797256469727\n",
      "129 9.225475311279297\n",
      "130 9.44271469116211\n",
      "131 9.520228385925293\n",
      "132 9.070595741271973\n",
      "133 9.32214069366455\n",
      "134 9.56581974029541\n",
      "135 9.330286979675293\n",
      "136 9.365900993347168\n",
      "137 9.183723449707031\n",
      "138 9.386184692382812\n",
      "139 9.240328788757324\n",
      "140 9.132784843444824\n",
      "141 9.8214750289917\n",
      "142 9.358959197998047\n",
      "143 9.275202751159668\n",
      "144 9.261845588684082\n",
      "145 9.575844764709473\n",
      "146 9.654975891113281\n",
      "147 9.812026023864746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# labels = labels.to(f'cuda:{model.device_ids[0]}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpine12/cl/work2/hikaru-si/development/exp_005/notebook/train.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/exp_005/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/exp_005/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# losses = []\n",
    "# model.train()\n",
    "# for epoch in range(args.max_epochs):\n",
    "#     for iter, batch in enumerate(dataloader):\n",
    "#         # inputs = {k: v.to(f'cuda:{model.device_ids[0]}') for k in [\"input_ids, bbox\", \"pixel_values\", \"attention_mask\"]}\n",
    "#         inputs = {k: batch[k] for k in [\"input_ids\", \"bbox\", \"pixel_values\", \"attention_mask\"]}\n",
    "#         logits = model.forward(inputs)\n",
    "#         t = []\n",
    "#         for i in range(len(batch[\"mask_position\"])):\n",
    "#             if len(batch[\"mask_position\"][i]) == 0:\n",
    "#                 continue\n",
    "#             t.append(logits[i][batch[\"mask_position\"][i]])\n",
    "#         logits = torch.cat(t)\n",
    "\n",
    "#         labels = torch.cat(batch[\"mask_label\"])\n",
    "#         # labels = labels.to(f'cuda:{model.device_ids[0]}')\n",
    "        \n",
    "#         loss = loss_fn(logits, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         losses.append(loss.item())\n",
    "#         if iter % 4 == 0:\n",
    "#             print(iter, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"epoch\": args.max_epochs,\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"loss_list\": losses,\n",
    "        \"model_state_dict\": model.module.to(\"cpu\").state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    f\"{args.output_model_dir}{args.output_file_name}\",\n",
    ")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load(args.output_model_dir+args.output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('exp_005')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46bb9fe42bf29cda1078546925c7ce66ab74e8066732926e47e293312739327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
