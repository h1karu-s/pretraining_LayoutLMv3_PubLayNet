{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tes():\n",
    "  cn = 0\n",
    "  for i in range(0, 10):\n",
    "    cn +=2\n",
    "  i = 10\n",
    "  return cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4):\n",
    "  print(i)\n",
    "  c =tes()\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 in [1, 3 , 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#再現性\n",
    "seed = 3407\n",
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def temp_np_seed(seed):\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        np.random.set_state(state)\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def temp_random_seed(seed):\n",
    "    state = random.getstate()\n",
    "    random.seed(seed)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        random.setstate(state)\n",
    "\n",
    "def plot_graph(args, epoch, iter_list, train_losses, val_losses):\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.xlabel(\"iter\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(iter_list, train_losses)\n",
    "    plt.plot(iter_list, val_losses)\n",
    "    plt.legend([\"train_loss\", \"valid_loss\"])\n",
    "    fig.savefig(f\"{args.output_model_dir}epoch_{epoch}/loss.png\")\n",
    "\n",
    "def plot_graph_2(args, epoch, iter_list, mi_losses, ml_losses, wpa_losses):\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.xlabel(\"iter\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(iter_list, mi_losses)\n",
    "    plt.plot(iter_list, ml_losses)\n",
    "    plt.plot(iter_list, wpa_losses)\n",
    "    plt.legend([\"ML\", \"MI\", \"WPA\"])\n",
    "    fig.savefig(f\"{args.output_model_dir}epoch_{epoch}/indiv_loss.png\")\n",
    "\n",
    "def plot_graph_3(args, epoch, iter_list, accesML, accesMI):\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.xlabel(\"iter\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.plot(iter_list, accesML)\n",
    "    plt.plot(iter_list, accesMI)\n",
    "    plt.legend([\"ML\", \"MI\"])\n",
    "    fig.savefig(f\"{args.output_model_dir}epoch_{epoch}/acces.png\")\n",
    "\n",
    "def save_hparams(args):\n",
    "    with open(f\"{args.output_model_dir}hparams.txt\", mode=\"w\") as f:\n",
    "        f.writelines(str(args.__dict__))\n",
    "\n",
    "#save fun \n",
    "def save_loss_epcoh(args, model, epoch, iter_list, train_losses, valid_losses, \\\n",
    "    ml_losses, mi_losses, wpa_losses, accesML, accesMI, optimizer, scheduler):\n",
    "\n",
    "    os.makedirs(f\"{args.output_model_dir}epoch_{epoch}\", exist_ok = True)\n",
    "    plot_graph(args, epoch, iter_list, train_losses, valid_losses) \n",
    "    plot_graph_2(args, epoch, iter_list, ml_losses, mi_losses, wpa_losses)\n",
    "    plot_graph_3(args, epoch, iter_list, accesML, accesMI)\n",
    "    torch.save(\n",
    "    {\n",
    "        \"epoch\": epoch,\n",
    "        \"iter_list\": iter_list,\n",
    "        \"train_loss_list\": train_losses,\n",
    "        \"valid_loss_list\": valid_losses,\n",
    "        \"ml_losses\": ml_losses,\n",
    "        \"mi_losses\": mi_losses,\n",
    "        \"wpa_losses\": wpa_losses,\n",
    "        \"accesML\": accesML,\n",
    "        \"accesMI\": accesMI,\n",
    "        \"model_state_dict\": model.module.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict()\n",
    "    },\n",
    "    f\"{args.output_model_dir}epoch_{epoch}/checkpoint.cpt\",\n",
    "    )\n",
    "    notification_slack(f\"epoch:{epoch}が終了しました。valid_lossは{valid_losses[-1]}です。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args, flush=True)\n",
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"GPU is not available.\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device_ids = list(range(torch.cuda.device_count()))\n",
    "\n",
    "tokenizer = LayoutLMv3Tokenizer(f\"{args.tokenizer_vocab_dir}vocab.json\", f\"{args.tokenizer_vocab_dir}merges.txt\")\n",
    "ids = range(tokenizer.vocab_size)\n",
    "vocab = tokenizer.convert_ids_to_tokens(ids)\n",
    "\n",
    "save_hparams(args)\n",
    "\n",
    "if not args.model_params is None:\n",
    "    checkpoint = torch.load(args.model_params, map_location=torch.device('cpu'))\n",
    "    config = AutoConfig.from_pretrained(args.model_name)\n",
    "    config.num_visual_tokens = 8192\n",
    "    model = LayoutLMv3ForPretraining(config)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "else:\n",
    "    config = AutoConfig.from_pretrained(args.model_name)\n",
    "    config.num_visual_tokens = 8192\n",
    "    model = LayoutLMv3ForPretraining(config)\n",
    "    Roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "    ## embedidng 層の重みをRobertaの重みで初期化\n",
    "    weight_size = model.state_dict()[\"model.embeddings.word_embeddings.weight\"].shape\n",
    "    for i in range(weight_size[0]):\n",
    "        model.state_dict()[\"model.embeddings.word_embeddings.weight\"][i] = \\\n",
    "        Roberta_model.state_dict()[\"embeddings.word_embeddings.weight\"][i]\n",
    "\n",
    "#modelをGPUへ\n",
    "model = torch.nn.DataParallel(model, device_ids = device_ids)\n",
    "model = model.to(f'cuda:{model.device_ids[0]}')\n",
    "\n",
    "#optimizer \n",
    "optimizer = AdamW(model.parameters(), lr=args.learning_rate, weight_decay=1e-2, betas=(0.9, 0.98))\n",
    "if not args.model_params is None:\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "#cross entropy\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#load input_file\n",
    "data = []\n",
    "input_names = os.listdir(args.input_file)\n",
    "if args.datasize is not None:\n",
    "    input_names = input_names[:args.datasize]\n",
    "notification_slack(f\"input_file_length: {len(input_names)}\")\n",
    "for file_name in input_names:\n",
    "    with open(f\"{args.input_file}{file_name}\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "        data += d\n",
    "notification_slack(f\"pretraing: datasize is {len(data)}\")\n",
    "#divide into train and valid\n",
    "n_train = math.floor(len(data) * args.ratio_train)\n",
    "train_data = data[:n_train]\n",
    "valid_data = data[n_train:]\n",
    "notification_slack(f\"pretraing: train_data is {len(train_data)}, valid_data is {len(valid_data)}.\")\n",
    "#create dataloader\n",
    "my_dataloader = My_Dataloader(vocab, random)\n",
    "train_dataloader = my_dataloader(train_data[:600], batch_size=args.batch_size, shuffle=True)\n",
    "valid_dataloader = my_dataloader(valid_data[:300], batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "#scheduler warm up lineary over fist 0.4% step\n",
    "iter_per_epoch = len(train_dataloader)\n",
    "num_warmup_steps = round((iter_per_epoch * args.max_epochs) * 0.048)\n",
    "if not args.model_params is None:\n",
    "    scheduler = get_constant_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_warmup_steps)\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "    print(\"not scheduler\", flush = True)\n",
    "else:\n",
    "    scheduler = get_constant_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "#define caluculation ml?loss\n",
    "def cal_ml_loss(text_logits, batch):\n",
    "    t = []\n",
    "    for i in range(len(batch[\"ml_position\"])):\n",
    "        if len(batch[\"ml_position\"][i]) == 0:\n",
    "            continue\n",
    "        t.append(text_logits[i][batch[\"ml_position\"][i]])\n",
    "    if len(t) == 0:\n",
    "        notification_slack(\"pretrain_3.py: len(t)==0\")\n",
    "        return 0\n",
    "    t_logits = torch.cat(t)\n",
    "    labels = torch.cat(batch[\"ml_label\"])\n",
    "    labels = labels.to(f'cuda:{model.device_ids[0]}')\n",
    "    loss = criterion(t_logits+ 1e-12, labels)\n",
    "    accML = (t_logits.argmax(-1) == labels).sum() / len(labels)\n",
    "    return loss, accML\n",
    "\n",
    "#define calculation mi_loss\n",
    "def cal_mi_loss(image_logits, batch):\n",
    "    image_logits = image_logits[:,1:]\n",
    "    if (image_logits.shape[0] != batch[\"bool_mi_pos\"].shape[0] or image_logits.shape[1] != batch[\"bool_mi_pos\"].shape[1]):\n",
    "        notification_slack(f\"diff imaeg_logit.shape and bool_mi_pos shape{image_logits.shape}, {batch['bool_mi_pos'].shape}\")\n",
    "        return 0\n",
    "    predict_visual_token = image_logits[batch[\"bool_mi_pos\"]].to(torch.float32)\n",
    "    labels = torch.cat(batch[\"mi_label\"])\n",
    "    labels = labels.to(f'cuda:{model.device_ids[0]}')\n",
    "    loss = criterion(predict_visual_token + 1e-12, labels)\n",
    "    accMI = (predict_visual_token.argmax(-1) == labels).sum() / len(labels)\n",
    "    return loss, accMI\n",
    "\n",
    "\n",
    "\n",
    "#define calculation wpa loss\n",
    "def cal_wpa_loss(wpa_logits, batch):\n",
    "    w_logits = wpa_logits[:,:512]\n",
    "    #padとlanguage maskのindexを除外\n",
    "    t  = []\n",
    "    for i in range(wpa_logits.shape[0]):\n",
    "        bool_index = torch.ones(512)\n",
    "        bool_index[batch[\"ml_position\"][i]] = 0\n",
    "        bool_index = bool_index * batch[\"attention_mask\"][i]\n",
    "        t.append(bool_index)\n",
    "    bool_indexes = torch.stack(t).to(torch.bool)\n",
    "    predict_label = w_logits[bool_indexes]\n",
    "    labels = batch[\"alignment_labels\"][bool_indexes].to(torch.long)\n",
    "    labels = labels.to(f'cuda:{model.device_ids[0]}')\n",
    "    loss = criterion(predict_label + 1e-12, labels)\n",
    "    return loss\n",
    "\n",
    "#validation step\n",
    "def validation():\n",
    "    losses = []\n",
    "    ml_losses = []\n",
    "    mi_losses = []\n",
    "    wpa_losses = []\n",
    "    accesML = []\n",
    "    accesMI = []\n",
    "    cont = 0\n",
    "    with torch.no_grad():\n",
    "        with temp_np_seed(3407):\n",
    "            with temp_random_seed(3407):\n",
    "                for batch in valid_dataloader:\n",
    "                    inputs = {k: batch[k].to(f\"cuda:{model.device_ids[0]}\") for k in [\"input_ids\", \"bbox\", \"pixel_values\", \"attention_mask\", \"bool_mi_pos\"]}\n",
    "                    text_logits, image_logits, wpa_logits = model.forward(inputs)\n",
    "                    ml_loss, accML = cal_ml_loss(text_logits, batch)\n",
    "                    mi_loss, accMI = cal_mi_loss(image_logits, batch)\n",
    "                    wpa_loss = cal_wpa_loss(wpa_logits, batch)\n",
    "                    val_loss = ml_loss + mi_loss + wpa_loss\n",
    "                    losses.append(val_loss.item())\n",
    "                    if ml_loss.item() == 0:\n",
    "                        cont +=1\n",
    "                    ml_losses.append(ml_loss.item())\n",
    "                    mi_losses.append(mi_loss.item())\n",
    "                    wpa_losses.append(wpa_loss.item())\n",
    "                    accesML.append(accML.item())\n",
    "                    accesMI.append(accMI.item())\n",
    "                    ave_losses = sum(losses) / len(losses)\n",
    "                    ave_ml = sum(ml_losses) / len(ml_losses)\n",
    "                    ave_mi =  sum(mi_losses) / len(mi_losses)\n",
    "                    ave_wpa = sum(wpa_losses) / len(wpa_losses)\n",
    "                    ave_accML = sum(accesML) / len(accesML)\n",
    "                    ave_accMI = sum(accesMI) / len(accesMI)\n",
    "                notification_slack(f\"loss == 0 num is {cont}\")\n",
    "                return ave_losses, (ave_ml, ave_mi, ave_wpa), (ave_accML, ave_accMI)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "ml_losses = []\n",
    "mi_losses = []\n",
    "wpa_losses = []\n",
    "accesML = []\n",
    "accesMI = []\n",
    "iter_list = []\n",
    "##epcoh\n",
    "if not args.model_params is None:\n",
    "    epochs = range(checkpoint[\"epoch\"] +1, args.max_epochs)\n",
    "    train_losses = checkpoint[\"train_loss_list\"]\n",
    "    valid_losses = checkpoint[\"valid_loss_list\"]\n",
    "    iter_list = checkpoint[\"iter_list\"]\n",
    "    ml_losses = checkpoint[\"ml_losses\"]\n",
    "    mi_losses = checkpoint[\"mi_losses\"]\n",
    "    wpa_losses = checkpoint[\"wpa_losses\"]\n",
    "    accesML = checkpoint[\"accesML\"]\n",
    "    accesMI = checkpoint[\"accesMI\"]\n",
    "    # iter_list = [0, 1314, 2628, 3942, 5265, 6\n",
    "    #570, 7884, 9198, 10512, 11826, 13140,13141, 14455, 15769, 17083, 18397, 19711, 21025, 22339, 23653, 24967, 26281]\n",
    "    print(epochs, flush=True)\n",
    "    print(train_losses, flush=True)\n",
    "    print(len(iter_list),iter_list, flush=True)\n",
    "else:\n",
    "    epochs = range(args.max_epochs)\n",
    "\n",
    "notification_slack(\"start training!\")\n",
    "iter_per_epoch = len(train_dataloader)\n",
    "print(\"iter: \", epochs[0] * iter_per_epoch, flush=True)\n",
    "model.train()\n",
    "for epoch in epochs:\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        iter = epoch * iter_per_epoch + i\n",
    "        inputs = {k: batch[k].to(f\"cuda:{model.device_ids[0]}\") for k in [\"input_ids\", \"bbox\", \"pixel_values\", \"attention_mask\", \"bool_mi_pos\"]}\n",
    "        text_logits, image_logits, wpa_logits = model.forward(inputs)\n",
    "        ml_loss, _ = cal_ml_loss(text_logits, batch)\n",
    "        mi_loss, _ = cal_mi_loss(image_logits, batch)\n",
    "        wpa_loss = cal_wpa_loss(wpa_logits, batch)\n",
    "\n",
    "        loss = ml_loss + mi_loss + wpa_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i % math.floor(iter_per_epoch*0.1) == 0:\n",
    "            iter_list.append(iter)\n",
    "            train_losses.append(loss.item())\n",
    "            val_loss, indv_loss, val_acc = validation()\n",
    "            valid_losses.append(val_loss)\n",
    "            ml_losses.append(indv_loss[0])\n",
    "            mi_losses.append(indv_loss[1])\n",
    "            wpa_losses.append(indv_loss[2])   \n",
    "            accesML.append(val_acc[0])\n",
    "            accesMI.append(val_acc[1])           \n",
    "            print(f\"{iter}  train_loss: {loss.item()}, valid_loss: {val_loss}\", flush=True)\n",
    "            notification_slack(\n",
    "                f\"e:{epochs}, iter:{iter},  train_loss: {loss.item()}, valid_loss: {val_loss}, idiv_loss:{str(indv_loss)}, acc:{str(val_acc)}\"\n",
    "                )\n",
    "    save_loss_epcoh(\n",
    "        args = args,\n",
    "        model = model,\n",
    "        epoch = epoch,\n",
    "        iter_list = iter_list,\n",
    "        train_losses = train_losses, \n",
    "        valid_losses = valid_losses, \n",
    "        ml_losses = ml_losses, \n",
    "        mi_losses = mi_losses, \n",
    "        wpa_losses = wpa_losses,\n",
    "        accesML = accesML,\n",
    "        accesMI = accesMI,\n",
    "        optimizer = optimizer, \n",
    "        scheduler = scheduler,\n",
    "        )\n",
    "    print(\"epoch\", epoch, loss.item(), flush=True)\n",
    "    \n",
    "# save_hparams(args)\n",
    "notification_slack(\"学習が無事に終わりました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('exp_005')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46bb9fe42bf29cda1078546925c7ce66ab74e8066732926e47e293312739327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
