{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import  pickle5 as pickle\n",
    "import math\n",
    "import contextlib\n",
    "import random \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoConfig, RobertaModel, LayoutLMv3Tokenizer\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "sys.path.append('../src')\n",
    "from model import  My_DataLoader\n",
    "from model.LayoutLMv3forMIM import LayoutLMv3ForPretraining\n",
    "from utils.slack import notification_slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--tokenizer_vocab_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--input_file\", type=str, required=True)\n",
    "parser.add_argument(\"--model_params\", type=str)\n",
    "parser.add_argument(\"--ratio_train\", type=float,default=0.9)\n",
    "parser.add_argument(\"--output_model_dir\", type=str, required=True)\n",
    "parser.add_argument(\"--output_file_name\", type=str, required=True)\n",
    "parser.add_argument(\"--model_name\", type=str, required=True)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=2)\n",
    "parser.add_argument(\"--learning_rate\", type=int, default=1e-4)\n",
    "parser.add_argument(\"--max_epochs\", type=int, default=3)\n",
    "parser.add_argument(\"--datasize\", type=int, default=2)\n",
    "args_list = [\"--tokenizer_vocab_dir\", \"../data/vocab/tokenizer_vocab/\",\"--input_file\",\n",
    "            \"../data/preprocessing_shared/wpa_10000/\",\n",
    "            \"--output_model_dir\", \"../data/train/test2/ \", \\\n",
    "            \"--output_file_name\", \"model.param\", \\\n",
    "            \"--batch_size\", \"32\", \\\n",
    "            \"--model_name\", \"microsoft/layoutlmv3-base\", \\\n",
    "            ]\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate_fn(self, batch):\n",
    "        output_dict = {}\n",
    "        for i, b in enumerate(batch):\n",
    "            #λ=1のポアソン分布からspanを生成\n",
    "            batch[i][\"mask_input_ids\"], batch[i][\"ml_position\"], batch[i][\"ml_label\"] = create_span_mask_for_ids(b[\"input_ids\"], 0.3, 153, self.vocab, 1, self.rng)\n",
    "            # if len(batch[i][\"ml_position\"]) == 0:\n",
    "            #     notification_slack(f\"maske lenght is 0!!!! and batch[i][input_ids]length is {len(batch[i]['input_ids'])}\")   \n",
    "        for i in [\"input_ids\", \"bbox\", \"pixel_values\"]:\n",
    "            padding_value=0\n",
    "            if i == \"mask_input_ids\":\n",
    "                padding_value = self.vocab.index(\"<pad>\")\n",
    "            output_dict[i] = torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.tensor(b[i]) for b in batch],\n",
    "                batch_first=True,\n",
    "                padding_value=padding_value\n",
    "            )\n",
    "            #pad_sequenceしても長さがseq_len以下の場合(not pixel values)\n",
    "            if i != \"pixel_values\" and output_dict[i].shape[1] != self.seq_len:\n",
    "                notification_slack(f\"padding_{i}:{output_dict[i].shape} < 512, do pading\")\n",
    "                pad_len= self.seq_len -output_dict[i].shape[1]\n",
    "                if i == \"input_ids\":\n",
    "                    #iput_ids > 0\n",
    "                    pad_tensor = torch.ones((output_dict[i].shape[0], pad_len), dtype=torch.long)*padding_value\n",
    "                else:\n",
    "                    #bbox > [0, 0, 0, 0]\n",
    "                    pad_tensor = torch.ones((output_dict[i].shape[0], pad_len, 4), dtype=torch.long)*padding_value\n",
    "\n",
    "                output_dict[i] = torch.cat((output_dict[i], pad_tensor), dim=1)\n",
    "\n",
    "        for i in [\"ml_position\", \"ml_label\"]:\n",
    "            output_dict[i] = [torch.LongTensor(b[i]) for b in batch]\n",
    "\n",
    "        output_dict[\"bool_mi_pos\"] = torch.cat([b[\"bool_masked_pos\"] for b in batch])\n",
    "        output_dict[\"mi_label\"] = [b[\"label\"] for b in batch]\n",
    "\n",
    "        attention_mask = self._create_attention_mask(output_dict[\"input_ids\"])\n",
    "        output_dict[\"attention_mask\"] = attention_mask\n",
    "        \n",
    "        #alignmentlabel for wpa\n",
    "        al_labels = torch.nn.utils.rnn.pad_sequence(\n",
    "            [b[\"alignment_labels\"] for b in batch],\n",
    "            batch_first=True,\n",
    "            padding_value=False\n",
    "        )\n",
    "        if al_labels.shape[1] != self.seq_len:\n",
    "            notification_slack(f\"padding_alignment_labels:{al_labels.shape} < 512, do pading\")\n",
    "            pad_len= self.seq_len - al_labels.shape[1]\n",
    "            pad_tensor = torch.zeros((al_labels.shape[0], pad_len)).to(torch.bool)\n",
    "            al_labels = torch.cat((al_labels, pad_tensor), dim=1)\n",
    "        \n",
    "        output_dict[\"alignment_labels\"] = al_labels\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-coding:utf-8-*-\n",
    "\n",
    "from ctypes import alignment\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import utils\n",
    "from utils.slack import notification_slack\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class My_Dataloader():\n",
    "    def __init__(self, vocab, random, seq_len=512,DataLoader=DataLoader):\n",
    "        self.vocab = vocab\n",
    "        self.DataLoader = DataLoader\n",
    "        self.random = random\n",
    "        self.seq_len = seq_len\n",
    "        self.rng = random\n",
    "    \n",
    "    def __call__(self, dataset,  batch_size, shuffle):\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True, collate_fn=self._collate_fn)\n",
    "    \n",
    "    def _create_attention_mask(self, x):\n",
    "        return torch.masked_fill(torch.ones(x.shape), x == self.vocab.index(\"<pad>\"), 0)\n",
    "\n",
    "    def _collate_fn(self, batch):\n",
    "        output_dict = {}\n",
    "        for i, b in enumerate(batch):\n",
    "            #λ=1のポアソン分布からspanを生成\n",
    "            batch[i][\"mask_input_ids\"], batch[i][\"ml_position\"], batch[i][\"ml_label\"] = create_span_mask_for_ids(b[\"input_ids\"], 0.3, 153, self.vocab, 1, self.rng)\n",
    "            # if len(batch[i][\"ml_position\"]) == 0:\n",
    "            #     notification_slack(f\"maske lenght is 0!!!! and batch[i][input_ids]length is {len(batch[i]['input_ids'])}\")   \n",
    "        for i in [\"mask_input_ids\", \"bbox\", \"pixel_values\"]:\n",
    "            padding_value=0\n",
    "            if i == \"mask_input_ids\":\n",
    "                padding_value = self.vocab.index(\"<pad>\")\n",
    "            output_dict[i] = torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.tensor(b[i]) for b in batch],\n",
    "                batch_first=True,\n",
    "                padding_value=padding_value\n",
    "            )\n",
    "            #pad_sequenceしても長さがseq_len以下の場合(not pixel values)\n",
    "            if i != \"pixel_values\" and output_dict[i].shape[1] != self.seq_len:\n",
    "                notification_slack(f\"padding_{i}:{output_dict[i].shape} < 512, do pading\")\n",
    "                pad_len= self.seq_len -output_dict[i].shape[1]\n",
    "                if i == \"mask_input_ids\":\n",
    "                    #iput_ids > 0\n",
    "                    pad_tensor = torch.ones((output_dict[i].shape[0], pad_len), dtype=torch.long)*padding_value\n",
    "                else:\n",
    "                    #bbox > [0, 0, 0, 0]\n",
    "                    pad_tensor = torch.ones((output_dict[i].shape[0], pad_len, 4), dtype=torch.long)*padding_value\n",
    "\n",
    "                output_dict[i] = torch.cat((output_dict[i], pad_tensor), dim=1)\n",
    "\n",
    "        for i in [\"ml_position\", \"ml_label\"]:\n",
    "            output_dict[i] = [torch.LongTensor(b[i]) for b in batch]\n",
    "\n",
    "        output_dict[\"bool_mi_pos\"] = torch.cat([b[\"bool_masked_pos\"] for b in batch])\n",
    "        output_dict[\"mi_label\"] = [b[\"label\"] for b in batch]\n",
    "\n",
    "        attention_mask = self._create_attention_mask(output_dict[\"mask_input_ids\"])\n",
    "        output_dict[\"attention_mask\"] = attention_mask\n",
    "        \n",
    "        #alignmentlabel for wpa\n",
    "        al_labels = torch.nn.utils.rnn.pad_sequence(\n",
    "            [b[\"alignment_labels\"] for b in batch],\n",
    "            batch_first=True,\n",
    "            padding_value=False\n",
    "        )\n",
    "        if al_labels.shape[1] != self.seq_len:\n",
    "            notification_slack(f\"padding_alignment_labels:{al_labels.shape} < 512, do pading\")\n",
    "            pad_len= self.seq_len - al_labels.shape[1]\n",
    "            pad_tensor = torch.zeros((al_labels.shape[0], pad_len)).to(torch.bool)\n",
    "            al_labels = torch.cat((al_labels, pad_tensor), dim=1)\n",
    "        \n",
    "        output_dict[\"alignment_labels\"] = al_labels\n",
    "\n",
    "        return output_dict\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import sys\n",
    "import fitz\n",
    "import numpy as np\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "MaskedLMInstance = collections.namedtuple(\"MaskedLmInstance\",\n",
    "                                          [\"index\", \"label\"])\n",
    "\n",
    "def create_span_mask_for_ids(token_ids, masked_lm_prob, max_predictions_per_seq, vocab_words, param , rng):\n",
    "    if 4 in token_ids:\n",
    "        print(\"error!!!!!! 4 in token_ids\")\n",
    "\n",
    "    cand_indexes = []\n",
    "    for i, id in enumerate(token_ids):\n",
    "        if id == vocab_words.index(\"<s>\") or id == vocab_words.index(\"</s>\") or id == vocab_words.index(\"<pad>\"):\n",
    "            continue\n",
    "\n",
    "        if len(cand_indexes) >= 1 and not vocab_words[id].startswith(\"Ġ\"):\n",
    "            cand_indexes[-1].append(i)\n",
    "        else:\n",
    "            cand_indexes.append([i])\n",
    "    output_tokens = list(token_ids)\n",
    "    # output_tokens = copy.deepcopy(token_ids)\n",
    "    #全単語×0.3(masked_lm_prob)がmaskの対象\n",
    "    num_to_predict = min(max_predictions_per_seq, \n",
    "                      max(1, int(round(len(cand_indexes) * masked_lm_prob))))\n",
    "    \n",
    "\n",
    "    span_count = 0\n",
    "    covered_indexes = [] #mask候補のリスト\n",
    "    covered_set = set()  # 被らないか確かめるための集合\n",
    "    #spanのword数が全words数の30%を超えたら終了\n",
    "    while (span_count < num_to_predict):\n",
    "\n",
    "        span_length = np.random.poisson(lam=param)\n",
    "        if span_count + span_length > num_to_predict or span_length == 0:\n",
    "            continue\n",
    "        #cand_indexesから初めの単語を決める\n",
    "        if len(cand_indexes) -(1 + span_length) <= 0:\n",
    "            break\n",
    "            # continue\n",
    "        start_index = rng.randint(0, len(cand_indexes)-(1 + span_length))\n",
    "        #span_lengthからsubword単位のspanの範囲を決める\n",
    "        covered_index = cand_indexes[start_index: start_index +span_length]\n",
    "        covered_index = list(itertools.chain.from_iterable(covered_index))\n",
    "        if covered_set.isdisjoint(set(covered_index)):\n",
    "            covered_set = covered_set | set(covered_index)\n",
    "            span_count += span_length\n",
    "            # print(span_length)\n",
    "            covered_indexes.append(covered_index)\n",
    "            # print(covered_indexes)\n",
    "\n",
    "    masked_lms = []\n",
    "    for span_index in covered_indexes:\n",
    "        if rng.random() < 0.8:\n",
    "            mask_token_id = vocab_words.index(\"<mask>\")\n",
    "            masked_tokens= [mask_token_id for _ in range(len(span_index))]\n",
    "            #maskした場所と元のtokenを記録\n",
    "            for i in span_index:\n",
    "                masked_lms.append(MaskedLMInstance(index=i, label=token_ids[i]))\n",
    "                # if token_ids[i] == 4:\n",
    "                    # print(f\"token_ids[i]==4!!!index = {i}, {token_ids}\")\n",
    "\n",
    "        else:\n",
    "            if rng.random() < 0.5:\n",
    "                masked_tokens = [token_ids[i] for i in span_index]\n",
    "\n",
    "            else:\n",
    "                #replace words\n",
    "                masked_tokens = [rng.randint(0, len(vocab_words) - 1) for _ in range(len(span_index))]\n",
    "         ###################################bag#####################################       \n",
    "        for i, index in enumerate(span_index):\n",
    "            output_tokens[index] = masked_tokens[i]\n",
    "####################################################################################\n",
    "    masked_lms = sorted(masked_lms, key=lambda x: x.index)\n",
    "\n",
    "    masked_lm_positions = []\n",
    "    masked_lm_labels = []    \n",
    "    for p in masked_lms:\n",
    "        masked_lm_positions.append(p.index)\n",
    "        masked_lm_labels.append(p.label)\n",
    "        \n",
    "    return (output_tokens, masked_lm_positions, masked_lm_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/cl/work2/hikaru-si/development/exp_005/exp/test.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Belm62/cl/work2/hikaru-si/development/exp_005/exp/test.ipynb#Y120sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m output_tokens\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "data1 = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "my_dataloader = My_Dataloader(vocab, random)\n",
    "train_dataloader = my_dataloader(data1, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'bbox', 'pixel_values', 'label', 'bool_masked_pos', 'alignment_labels'])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '<mask>')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "data4 = []\n",
    "for d in data1:\n",
    "  if 4 in d[\"input_ids\"]:\n",
    "    cnt += 4\n",
    "    data4.append(d)\n",
    "\n",
    "cnt, vocab[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for input in train_dataloader:\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = input[\"mask_input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "input[\"input_ids\"] = input.pop(\"mask_input_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bbox', 'pixel_values', 'ml_position', 'ml_label', 'bool_mi_pos', 'mi_label', 'attention_mask', 'alignment_labels', 'input_ids'])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     4,     4,  ...,     1,     1,     1],\n",
       "        [    0,     4, 10445,  ...,     1,     1,     1],\n",
       "        [    0,   337, 14003,  ...,   446,  1118,     2],\n",
       "        ...,\n",
       "        [    0,  4664,  5459,  ...,  3274,  1668,     2],\n",
       "        [    0,   939,  3348,  ...,     1,     1,     1],\n",
       "        [    0, 28849,  8048,  ...,     1,     1,     1]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     4,     4,  ...,     1,     1,     1],\n",
       "        [    0,     4, 10445,  ...,     1,     1,     1],\n",
       "        [    0,   337, 14003,  ...,   446,  1118,     2],\n",
       "        ...,\n",
       "        [    0,  4664,  5459,  ...,  3274,  1668,     2],\n",
       "        [    0,   939,  3348,  ...,     1,     1,     1],\n",
       "        [    0, 28849,  8048,  ...,     1,     1,     1]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-100, 2, 3, 4, 5], [-100, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "b = a\n",
    "b[0] = -100\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('exp_005')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46bb9fe42bf29cda1078546925c7ce66ab74e8066732926e47e293312739327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
